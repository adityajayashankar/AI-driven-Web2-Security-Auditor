import os
import json
import dataclasses
import requests
from collections import Counter
from dotenv import load_dotenv

from agents.llm_clients.openrouter_client import OpenRouterClient
from agents.planner.planner_llm import LLMPlanner
from agents.entrypoint import run_with_planner
from sast.scope import ScopePolicy

load_dotenv()

class EnhancedJSONEncoder(json.JSONEncoder):
    def default(self, o):
        if dataclasses.is_dataclass(o):
            return dataclasses.asdict(o)
        return super().default(o)

# 1. Initialize AI Planner
client = OpenRouterClient(
    api_key=os.environ.get("OPENROUTER_API_KEY", "invalid-key-placeholder"),
    model="google/gemma-3n-e2b-it:free",
)
planner = LLMPlanner(client)

# 2. Define Scope Policy [FIXED]
scope = ScopePolicy(
    allowed_repo_prefixes=["https://github.com/", "http"],
    allowed_domains=[
        "localhost", 
        "127.0.0.1", 
        "example.com", 
        "notion.site", 
        "host.docker.internal", 
        "testphp.vulnweb.com",
        "juice-shop.herokuapp.com"  # <--- [FIX] Added this allowed domain
    ],
    safe_mode=False, 
    max_requests=1000,
)

# 3. Load Configuration
input_env = os.environ.get("SCAN_INPUT_JSON")

if input_env:
    print("ðŸ“¥ Loading configuration from API...")
    try:
        scan_input = json.loads(input_env)
    except json.JSONDecodeError as e:
        print(f"âŒ Failed to parse SCAN_INPUT_JSON: {e}")
        exit(1)
else:
    print("âš ï¸ No API input found. Using default test targets (Manual Run).")
    scan_input = {
        "run_id": "manual-test",
        "repo_path": "https://github.com/juice-shop/juice-shop",
        "languages": ["javascript"],
        "dast": {"target_url": "https://juice-shop.herokuapp.com"},
        "dependencies": ["package.json"]
    }

target = scan_input.get('repo_path') or scan_input.get('dast', {}).get('target_url') or "unknown-target"
print(f"ðŸš€ Starting Security Scan for: {target}")

# 4. Run the Security Pipeline
try:
    result = run_with_planner(
        input=scan_input,
        planner=planner,
        scope=scope,
    )
except Exception as e:
    print(f"âŒ Critical Pipeline Error: {e}")
    result = {
        "run_id": scan_input.get("run_id"),
        "status": "failed",
        "error": str(e),
        "tools": [],
        "findings": []
    }

# 5. Post-Processing
clean_findings = []
if "findings" in result:
    for f in result["findings"]:
        if isinstance(f, dict):
             f["repo"] = target
             clean_findings.append(f)
        elif hasattr(f, "to_dict"):
             f.repo = target
             clean_findings.append(f.to_dict())
        else:
            as_dict = dataclasses.asdict(f)
            as_dict["repo"] = target
            clean_findings.append(as_dict)

result["findings"] = clean_findings

# 6. Output Summary
print("\n=== FINAL RESULT ===")
print("TOOLS RUN:", result.get("tools", []))
print("TOTAL FINDINGS:", len(clean_findings))

if clean_findings:
    categories = Counter(f.get("category", "UNKNOWN") for f in clean_findings)
    print("FINDINGS BY CATEGORY:", dict(categories))

# 7. Persistence
output_path = "scan_results.json"
try:
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result, f, indent=2, cls=EnhancedJSONEncoder) 
    print(f"\nâœ… Scan artifacts saved to: {output_path}")
except Exception as e:
    print(f"\nâŒ Failed to save artifacts locally: {e}")

callback_url = scan_input.get("callback_url")
if callback_url:
    print(f"\nðŸ“¡ Sending results to Control Plane: {callback_url}")
    try:
        requests.post(callback_url, json=result, timeout=10)
        print("âœ… Results successfully stored in Database!")
    except Exception:
        pass